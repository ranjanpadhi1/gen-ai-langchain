{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model using Groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019CD791ACB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019CD79199F0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat conversion without memory / chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello John! üëã \n",
       "\n",
       "It's nice to meet you. What can I do for you today? üòä \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(model.invoke(\"Hi, I am John\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As an AI, I have no memory of past conversations and don't know who you are.\n",
       "\n",
       "If you'd like to tell me about yourself, I'm happy to listen! üòä  What's your name? What are you interested in?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(model.invoke(\"Hi, Who am I?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remembering as per previous conversation or messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are Ranjan, a Senior Software Engineer at J.P.Morgan.  \n",
       "\n",
       "I remember that from our previous conversation.  üòä  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from IPython.display import Markdown\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"Hi, I am Ranjan and I work as Senior Software Engineer at J.P.Morgan\"),\n",
    "    SystemMessage(\"Remember what user is saying\"),\n",
    "    HumanMessage(\"Who am I?\"),\n",
    "]\n",
    "\n",
    "Markdown(model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message History using `ChatMessageHistory` and `session_id`\n",
    "ChatMessageHistory passes entire consversation history as messages(as above) whenever a new message is send to the model, thus remembers the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As a large language model, I have no memory of past conversations and I don't know you personally.\n",
       "\n",
       "If you'd like to tell me about yourself, I'm happy to listen!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store= {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat_1\"}}\n",
    "Markdown(with_message_history.invoke(\"Hi, do you know me?\", config).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Ranjan, it's nice to meet you! \n",
       "\n",
       "That's impressive, working as a Senior Software Engineer at J.P. Morgan. What kind of software do you specialize in?  üòä  \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(with_message_history.invoke(\"Hi, My name is Ranjan, working as senior software Engineer at J.P.Morgan\", config).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are Ranjan, a Senior Software Engineer at J.P. Morgan!  \n",
       "\n",
       "Is there anything else you'd like to know about yourself, or would you like to talk about something else?  üòä  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(with_message_history.invoke(\"Hi, Who am I?\", config).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Archana! \n",
       "\n",
       "It's nice to meet you.  \n",
       "\n",
       "I understand you're an MTS 3 at VMware India. That's great! VMware is doing some really interesting work. \n",
       "\n",
       "Is there anything I can help you with today? \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"session_id\": \"chat_2\"}}\n",
    "\n",
    "Markdown(with_message_history.invoke(\"Hi, I am Archana, working as MTS 3 at VMWare India\", config2).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are Archana, an MTS 3 at VMware India, as you told me earlier.  \n",
       "\n",
       "Is there something specific you're wondering about your identity or role? \n",
       "\n",
       "Perhaps you're feeling a bit lost or confused?  I'm here to listen and help in any way I can.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(with_message_history.invoke(\"Hi, Who am I?\", config2).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, I do!  You are Ranjan, a Senior Software Engineer at J.P. Morgan.  \n",
       "\n",
       "What can I do for you today? üòä  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(with_message_history.invoke(\"Hi, Do you remember me?\", config).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, do you know me?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As a large language model, I have no memory of past conversations and I don't know you personally.\\n\\nIf you'd like to tell me about yourself, I'm happy to listen!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 16, 'total_tokens': 60, 'completion_time': 0.08, 'prompt_time': 8.1579e-05, 'queue_time': 0.013529731, 'total_time': 0.080081579}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2464f9ee-55d7-497d-852e-7ed9b9e7dabc-0', usage_metadata={'input_tokens': 16, 'output_tokens': 44, 'total_tokens': 60}), HumanMessage(content='Hi, My name is Ranjan, working as senior software Engineer at J.P.Morgan', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Ranjan, it's nice to meet you! \\n\\nThat's impressive, working as a Senior Software Engineer at J.P. Morgan. What kind of software do you specialize in?  üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 87, 'total_tokens': 135, 'completion_time': 0.087272727, 'prompt_time': 0.002374162, 'queue_time': 0.011333868, 'total_time': 0.089646889}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-be93a7be-7b96-4845-862e-bf61ce77f0f5-0', usage_metadata={'input_tokens': 87, 'output_tokens': 48, 'total_tokens': 135}), HumanMessage(content=\"Hi, What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='You are Ranjan.  üòä \\n\\nI remember our earlier conversation!  \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 150, 'total_tokens': 169, 'completion_time': 0.034545455, 'prompt_time': 0.005338461, 'queue_time': 0.008098518999999998, 'total_time': 0.039883916}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b0fee68f-b719-4282-9818-ab77b45b4a71-0', usage_metadata={'input_tokens': 150, 'output_tokens': 19, 'total_tokens': 169}), HumanMessage(content=\"Hi, What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Ranjan. üòä  \\n\\nIs there anything else I can help you with?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 185, 'total_tokens': 208, 'completion_time': 0.041818182, 'prompt_time': 0.005553311, 'queue_time': 0.007613819000000001, 'total_time': 0.047371493}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b34e2e11-713f-4a21-918c-b5f6997643b8-0', usage_metadata={'input_tokens': 185, 'output_tokens': 23, 'total_tokens': 208}), HumanMessage(content=\"Hi, What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='This is a fun little game!  \\n\\nYour name is Ranjan.  \\n\\nDo you want to try another question? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 224, 'total_tokens': 254, 'completion_time': 0.054545455, 'prompt_time': 0.007194865, 'queue_time': 0.006246895000000001, 'total_time': 0.06174032}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-29d63114-517f-4afc-ae35-cae346bea9fa-0', usage_metadata={'input_tokens': 224, 'output_tokens': 30, 'total_tokens': 254}), HumanMessage(content='Hi, Who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are Ranjan, a Senior Software Engineer at J.P. Morgan!  \\n\\nIs there anything else you'd like to know about yourself, or would you like to talk about something else?  üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 268, 'total_tokens': 315, 'completion_time': 0.085454545, 'prompt_time': 0.010462794, 'queue_time': 0.002840724000000001, 'total_time': 0.095917339}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9133c836-0ab6-4169-9b8b-b72e8ddcd4b1-0', usage_metadata={'input_tokens': 268, 'output_tokens': 47, 'total_tokens': 315}), HumanMessage(content='Hi, Do you remember me?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, I do!  You are Ranjan, a Senior Software Engineer at J.P. Morgan.  \\n\\nWhat can I do for you today? üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 330, 'total_tokens': 367, 'completion_time': 0.067272727, 'prompt_time': 0.013045125, 'queue_time': 0.002774063000000002, 'total_time': 0.080317852}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6944cb4e-b6a1-4073-80f4-26cf8ee6548b-0', usage_metadata={'input_tokens': 330, 'output_tokens': 37, 'total_tokens': 367})]),\n",
       " 'chat_2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, I am Archana, working as MTS 3 at VMWare India', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Archana! \\n\\nIt's nice to meet you.  \\n\\nI understand you're an MTS 3 at VMware India. That's great! VMware is doing some really interesting work. \\n\\nIs there anything I can help you with today? \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 26, 'total_tokens': 85, 'completion_time': 0.107272727, 'prompt_time': 0.000171079, 'queue_time': 0.01320021, 'total_time': 0.107443806}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-535983bb-0233-43d6-ad79-daf55f121fe4-0', usage_metadata={'input_tokens': 26, 'output_tokens': 59, 'total_tokens': 85}), HumanMessage(content='Hi, Who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You are Archana, an MTS 3 at VMware India, as you told me earlier.  \\n\\nIs there something specific you're wondering about your identity or role? \\n\\nPerhaps you're feeling a bit lost or confused?  I'm here to listen and help in any way I can.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 98, 'total_tokens': 164, 'completion_time': 0.12, 'prompt_time': 0.002509361, 'queue_time': 0.011153518, 'total_time': 0.122509361}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5aefd902-a2a2-450d-b0f6-fd1082025898-0', usage_metadata={'input_tokens': 98, 'output_tokens': 66, 'total_tokens': 164})])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat History along with ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•á ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§π‡•à‡§Ç‡•§ \n",
       "\n",
       "‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á 2014 ‡§∏‡•á ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§ï‡§Æ‡§æ‡§® ‡§∏‡§Ç‡§≠‡§æ‡§≤‡•Ä ‡§π‡•à ‡§î‡§∞ 2019 ‡§Æ‡•á‡§Ç ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ö‡•Å‡§®‡•á ‡§ó‡§è ‡§π‡•à‡§Ç‡•§ ‡§Æ‡•ã‡§¶‡•Ä ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ ‡§™‡§æ‡§∞‡•ç‡§ü‡•Ä (‡§≠‡§æ‡§ú‡§™‡§æ) ‡§ï‡•á ‡§®‡•á‡§§‡§æ ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§ó‡•Å‡§ú‡§∞‡§æ‡§§ ‡§ï‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§≠‡•Ä ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ \n",
       "\n",
       "‡§â‡§®‡§ï‡•á ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§µ‡§ø‡§ö‡§æ‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§µ‡§æ‡§¶, ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§î‡§∞ ‡§∏‡§æ‡§Æ‡§æ‡§ú‡§ø‡§ï ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§ \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer all question based on your ability in {language}\"),\n",
    "    MessagesPlaceholder(\"messages\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "Markdown(chain.invoke({\"messages\": [HumanMessage(\"Who is Narendra Modi?\")], \"language\": \"Hindi\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∞‡§Ç‡§ú‡§®! \n",
       "\n",
       "‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§  ‡§è‡§ï ‡§∏‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç J.P.Morgan ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡§æ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§π‡•à‡•§ \n",
       "\n",
       "‡§Ü‡§™‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§™‡•Ç‡§õ‡•á ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Æ‡•à‡§Ç ‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡•Ç‡§Ç! \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "\n",
    "config3 = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "Markdown(with_history.invoke({\"messages\": [HumanMessage(\"I am Ranjan, I work as Senior Software Engineer at J.P.Morgan.\")], \"language\": \"Hindi\"}, config3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‡§Ü‡§™ ‡§∞‡§Ç‡§ú‡§® ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§ú‡•á.‡§™‡•Ä. ‡§Æ‡•ã‡§∞‡•ç‡§ó‡§® ‡§Æ‡•á‡§Ç ‡§∏‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞ ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ \n",
       "\n",
       "‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(with_history.invoke({\"messages\": \"Who am I?\", \"language\": \"Hindi\"}, config3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
